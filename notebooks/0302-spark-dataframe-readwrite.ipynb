{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f707679",
   "metadata": {},
   "source": [
    "# Spark DataFrame ReadWrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb24b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc0ab0c",
   "metadata": {},
   "source": [
    "## CSV Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8894bc0e",
   "metadata": {},
   "source": [
    "### DataFrameReader: `read`\n",
    "Read data from CSV file without header assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"s3a://datalake/examples/zipcodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4833f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e098a",
   "metadata": {},
   "source": [
    "Check to ensure that the first line is header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febbcfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(n=2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e74dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.option(\"header\", True).csv(\"s3a://datalake/examples/zipcodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c979474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4354dd6",
   "metadata": {},
   "source": [
    "More options to control how to read a CSV data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.read.options(header=\"True\", delimiter=\",\").csv(\"s3a://datalake/examples/zipcodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba056dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e31ea36",
   "metadata": {},
   "source": [
    "Load data with `StructType` schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = (\n",
    "    T.StructType()\n",
    "      .add(\"RecordNumber\",T.IntegerType(),True)\n",
    "      .add(\"Zipcode\",T.IntegerType(),True)\n",
    "      .add(\"ZipCodeType\",T.StringType(),True)\n",
    "      .add(\"City\",T.StringType(),True)\n",
    "      .add(\"State\",T.StringType(),True)\n",
    "      .add(\"LocationType\",T.StringType(),True)\n",
    "      .add(\"Lat\",T.DoubleType(),True)\n",
    "      .add(\"Long\",T.DoubleType(),True)\n",
    "      .add(\"Xaxis\",T.IntegerType(),True)\n",
    "      .add(\"Yaxis\",T.DoubleType(),True)\n",
    "      .add(\"Zaxis\",T.DoubleType(),True)\n",
    "      .add(\"WorldRegion\",T.StringType(),True)\n",
    "      .add(\"Country\",T.StringType(),True)\n",
    "      .add(\"LocationText\",T.StringType(),True)\n",
    "      .add(\"Location\",T.StringType(),True)\n",
    "      .add(\"Decommisioned\",T.BooleanType(),True)\n",
    "      .add(\"TaxReturnsFiled\",T.StringType(),True)\n",
    "      .add(\"EstimatedPopulation\",T.IntegerType(),True)\n",
    "      .add(\"TotalWages\",T.IntegerType(),True)\n",
    "      .add(\"Notes\",T.StringType(),True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498a6160",
   "metadata": {},
   "source": [
    "Alternative to use directly `csv()` is to use `load()` with `format()` (This is generic way for loading other data source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7483ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_schema = (\n",
    "    spark\n",
    "        .read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", True)\n",
    "        .schema(schema)\n",
    "        .load(\"s3a://datalake/examples/zipcodes.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_schema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a64db83",
   "metadata": {},
   "source": [
    "### DataFrameWriter: `write`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94992679",
   "metadata": {},
   "source": [
    "Test writing output after casting data with the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42140d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_with_schema\n",
    "     .write\n",
    "     .option(\"header\", True)\n",
    "     .csv(\"s3a://datalake/spark_output/zipcodes123\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc0570b",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2b7023",
   "metadata": {},
   "source": [
    "### a document in a line\n",
    "\n",
    "If a JSON file contains a docuemnt in a line, we can directly read it without any options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6748e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"s3a://datalake/examples/zipcodes.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef71a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e67244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(n=2, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07505f",
   "metadata": {},
   "source": [
    "### a document span multiple line\n",
    "\n",
    "If a JSON file contains multiple items in an array, but need parsing multiline for an item. Use `multiline` optin to read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7967bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark\n",
    "        .read\n",
    "        .option(\"multiline\",  \"true\")\n",
    "        .json(\"s3a://datalake/examples/multiline-zipcode.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585342ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fef7e8",
   "metadata": {},
   "source": [
    "### read multiple json files\n",
    "\n",
    "Use array of file names with `json` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.json([\"s3a://datalake/examples/zipcode2.json\", \"s3a://datalake/examples/zipcode1.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.show(n=2, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91afba",
   "metadata": {},
   "source": [
    "Sometimes it is easier to use wildcard `*` to indicate all files in path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.read.json(\"s3a://datalake/examples/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb416846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.show(n=2, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f249059",
   "metadata": {},
   "source": [
    "As normally creating a dataframe, we can specifiy schema for loaded JSON documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0165154",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = T.StructType([\n",
    "      T.StructField(\"RecordNumber\",T.IntegerType(),True),\n",
    "      T.StructField(\"Zipcode\",T.IntegerType(),True),\n",
    "      T.StructField(\"ZipCodeType\",T.StringType(),True),\n",
    "      T.StructField(\"City\",T.StringType(),True),\n",
    "      T.StructField(\"State\",T.StringType(),True),\n",
    "      T.StructField(\"LocationType\",T.StringType(),True),\n",
    "      T.StructField(\"Lat\",T.DoubleType(),True),\n",
    "      T.StructField(\"Long\",T.DoubleType(),True),\n",
    "      T.StructField(\"Xaxis\",T.IntegerType(),True),\n",
    "      T.StructField(\"Yaxis\",T.DoubleType(),True),\n",
    "      T.StructField(\"Zaxis\",T.DoubleType(),True),\n",
    "      T.StructField(\"WorldRegion\",T.StringType(),True),\n",
    "      T.StructField(\"Country\",T.StringType(),True),\n",
    "      T.StructField(\"LocationText\",T.StringType(),True),\n",
    "      T.StructField(\"Location\",T.StringType(),True),\n",
    "      T.StructField(\"Decommisioned\",T.BooleanType(),True),\n",
    "      T.StructField(\"TaxReturnsFiled\",T.StringType(),True),\n",
    "      T.StructField(\"EstimatedPopulation\",T.IntegerType(),True),\n",
    "      T.StructField(\"TotalWages\",T.IntegerType(),True),\n",
    "      T.StructField(\"Notes\",T.StringType(),True)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdea571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_schema = (\n",
    "    spark\n",
    "        .read\n",
    "        .schema(schema)\n",
    "        .json(\"s3a://datalake/examples/zipcodes.json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b239ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9092c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_schema.show(n=2, vertical=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
