{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52686a",
   "metadata": {},
   "source": [
    "## Convert column name to convention\n",
    "\n",
    "It is possible that there are variety of naming columns or fields of raw data, however we should have a common convention for our data in datalake so that data users can use it with intuition and no confusion.\n",
    "\n",
    "As our tables in raw have coluns in `camel-casing` convention, but we need `snake-casing` in our datalake.\n",
    "\n",
    "![Data Models](https://www.mysqltutorial.org/wp-content/uploads/2009/12/MySQL-Sample-Database-Schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e00e52",
   "metadata": {},
   "source": [
    "For an example, `productlines` need to change columns as following:\n",
    "\n",
    "- `productLine` changed to `product_line`\n",
    "- `textDescription` chagned to `text_description`\n",
    "- `htmlDescription` changed to `html_description`\n",
    "- `image` nothing to change\n",
    "\n",
    "We need to transform column names and store all tranformed models in: `s3a://datalake/exercises/bronze/classicmodels/<table>.parquet`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d04303",
   "metadata": {},
   "source": [
    "## Productlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table raw_productlines\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/raw/classicmodels/productlines.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ec6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table bronze_productlines (\n",
    "    product_line string, \n",
    "    text_description string,\n",
    "    html_description string,\n",
    "    image binary\n",
    ")\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/bronze/classicmodels/productlines.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a14a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert overwrite bronze_productlines\n",
    "\n",
    "select * from raw_productlines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/bronze/classicmodels/productlines.parquet\")\n",
    "\n",
    "assert sorted(df.columns) == ['html_description', 'image', 'product_line', 'text_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca3d79",
   "metadata": {},
   "source": [
    "## Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6613119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table raw_products\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/raw/classicmodels/products.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c076c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table bronze_products (\n",
    "    product_code string,\n",
    "    product_name string,\n",
    "    product_line string,\n",
    "    product_scale string,\n",
    "    product_vendor string,\n",
    "    product_description string,\n",
    "    quantity_in_stock integer,\n",
    "    buy_price decimal(10, 2),\n",
    "    msrp decimal(10, 2)\n",
    ")\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/bronze/classicmodels/products.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d24cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert overwrite bronze_products\n",
    "\n",
    "select * from raw_products\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd347a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/bronze/classicmodels/products.parquet\")\n",
    "\n",
    "assert sorted(df.columns) == ['buy_price', 'msrp', 'product_code',\n",
    "                              'product_description', 'product_line', 'product_name',\n",
    "                              'product_scale', 'product_vendor', 'quantity_in_stock']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d30550",
   "metadata": {},
   "source": [
    "## Employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table raw_employees\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/raw/classicmodels/employees.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc093a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table bronze_employees (\n",
    "    employee_number integer,\n",
    "    last_name string,\n",
    "    first_name string,\n",
    "    extension string,\n",
    "    email string,\n",
    "    office_code string,\n",
    "    reports_to integer,\n",
    "    job_title string\n",
    ")\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/bronze/classicmodels/employees.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787bea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert overwrite bronze_employees\n",
    "\n",
    "select * from raw_employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/bronze/classicmodels/employees.parquet\")\n",
    "\n",
    "assert sorted(df.columns) == ['email', 'employee_number', 'extension',\n",
    "                              'first_name', 'job_title', 'last_name',\n",
    "                              'office_code', 'reports_to']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6856a5c1",
   "metadata": {},
   "source": [
    "## Offices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85090ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table raw_offices\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/raw/classicmodels/offices.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table bronze_offices (\n",
    "    office_code string,\n",
    "    city string,\n",
    "    phone string,\n",
    "    address_line_1 string,\n",
    "    address_line_2 string,\n",
    "    state string,\n",
    "    country string,\n",
    "    postal_code string,\n",
    "    territory string\n",
    ")\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/bronze/classicmodels/offices.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce660f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert overwrite bronze_offices\n",
    "\n",
    "select * from raw_offices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c9a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/bronze/classicmodels/offices.parquet\")\n",
    "\n",
    "assert sorted(df.columns) == ['address_line_1', 'address_line_2', 'city',\n",
    "                              'country', 'office_code', 'phone',\n",
    "                              'postal_code', 'state', 'territory']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4491128",
   "metadata": {},
   "source": [
    "## Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table raw_customers\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/raw/classicmodels/customers.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table bronze_customers (\n",
    "    customer_number integer,\n",
    "    customer_name string,\n",
    "    contact_last_name string,\n",
    "    contact_first_name string,\n",
    "    phone string,\n",
    "    address_line_1 string,\n",
    "    address_line_2 string,\n",
    "    city string,\n",
    "    state string,\n",
    "    postal_code string,\n",
    "    country string,\n",
    "    sales_rep_employee_number integer,\n",
    "    credit_limit decimal(10,2)\n",
    ")\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/bronze/classicmodels/customers.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa25f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert overwrite bronze_customers\n",
    "\n",
    "select * from raw_customers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/bronze/classicmodels/customers.parquet\")\n",
    "\n",
    "assert sorted(df.columns) == ['address_line_1', 'address_line_2', 'city',\n",
    "                              'contact_first_name', 'contact_last_name', 'country',\n",
    "                              'credit_limit', 'customer_name', 'customer_number',\n",
    "                              'phone', 'postal_code', 'sales_rep_employee_number',\n",
    "                              'state']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41399035",
   "metadata": {},
   "source": [
    "## Payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f71a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table raw_payments\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/raw/classicmodels/payments.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e72e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table bronze_payments (\n",
    "    customer_number integer,\n",
    "    check_number string,\n",
    "    payment_date date,\n",
    "    amount decimal(10, 2)\n",
    ")\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/bronze/classicmodels/payments.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c46a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert overwrite bronze_payments\n",
    "\n",
    "select * from raw_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/bronze/classicmodels/payments.parquet\")\n",
    "\n",
    "assert sorted(df.columns) == ['amount', 'check_number', 'customer_number', 'payment_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a28e2",
   "metadata": {},
   "source": [
    "## Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table raw_orders\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/raw/classicmodels/orders.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fc702",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table bronze_orders (\n",
    "    order_number integer,\n",
    "    order_date date,\n",
    "    required_date date,\n",
    "    shipped_date date,\n",
    "    status string,\n",
    "    comments string,\n",
    "    customer_number integer\n",
    ")\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/bronze/classicmodels/orders.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert overwrite bronze_orders\n",
    "\n",
    "select * from raw_orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/bronze/classicmodels/orders.parquet\")\n",
    "\n",
    "assert sorted(df.columns) == ['comments', 'customer_number', 'order_date',\n",
    "                              'order_number', 'required_date', 'shipped_date',\n",
    "                              'status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c1660",
   "metadata": {},
   "source": [
    "## Orderdetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7dc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table raw_orderdetails\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/raw/classicmodels/orderdetails.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a985d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "describe raw_orderdetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a92d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "create external table bronze_orderdetails (\n",
    "    order_number integer,\n",
    "    product_code string,\n",
    "    quantity_ordered int,\n",
    "    price_each decimal(10, 2),\n",
    "    order_line_number integer\n",
    ")\n",
    "\n",
    "using parquet\n",
    "\n",
    "location 's3a://datalake/exercises/bronze/classicmodels/orderdetails.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd47d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert overwrite bronze_orderdetails\n",
    "\n",
    "select * from raw_orderdetails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/bronze/classicmodels/orderdetails.parquet\")\n",
    "\n",
    "assert sorted(df.columns) == ['order_line_number', 'order_number', 'price_each', 'product_code', 'quantity_ordered']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
