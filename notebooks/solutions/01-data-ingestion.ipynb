{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de744d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff8aab",
   "metadata": {},
   "source": [
    "# Extract data from source to datalake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e160bfd5",
   "metadata": {},
   "source": [
    "In this exercise, we will extract data from datasource, which is MySQL server database called `classicmodels`, and load the extracted into datalake. We will process those data later exercises.\n",
    "\n",
    "![Data Model](https://www.mysqltutorial.org/wp-content/uploads/2009/12/MySQL-Sample-Database-Schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e714b5",
   "metadata": {},
   "source": [
    "The extracted data should be located at `s3a://datalake/raw/classicmodels/<table_name>.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def load_table_df(table_name) -> DataFrame:\n",
    "    return (\n",
    "        spark\n",
    "            .read\n",
    "            .format(\"jdbc\")\n",
    "            .option(\"driver\", \"com.mysql.jdbc.Driver\")\n",
    "            .option(\"url\", \"jdbc:mysql://localhost/classicmodels\")\n",
    "            .option(\"dbtable\", table_name)\n",
    "            .option(\"user\", \"root\")\n",
    "            .option(\"password\", \"\")\n",
    "            .load()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c383cc",
   "metadata": {},
   "source": [
    "## productlines table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e420c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "productlines = load_table_df(\"productlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead297b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    productlines\n",
    "        .write\n",
    "        .format(\"parquet\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"s3a://datalake/exercises/raw/classicmodels/productlines.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09fdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/raw/classicmodels/productlines.parquet\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beec6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert row_count == 7, \"Productlines was not loaded complete.\"\n",
    "\n",
    "print(\"Productlines was loaded complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc53738c",
   "metadata": {},
   "source": [
    "## products table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = load_table_df(\"products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    products\n",
    "        .write\n",
    "        .format(\"parquet\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"s3a://datalake/exercises/raw/classicmodels/products.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/raw/classicmodels/products.parquet\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943990bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert row_count == 110, \"Products was not loaded complete.\"\n",
    "\n",
    "print(\"Products was loaded complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45646b0c",
   "metadata": {},
   "source": [
    "## offices table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "offices = load_table_df(\"offices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea27a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    offices\n",
    "        .write\n",
    "        .format(\"parquet\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"s3a://datalake/exercises/raw/classicmodels/offices.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/raw/classicmodels/offices.parquet\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5860f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert row_count == 7, \"Offices was not loaded complete.\"\n",
    "\n",
    "print(\"Offices was loaded complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce4627c",
   "metadata": {},
   "source": [
    "## employees table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e76a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = load_table_df(\"employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    employees\n",
    "        .write\n",
    "        .format(\"parquet\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"s3a://datalake/exercises/raw/classicmodels/employees.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/raw/classicmodels/employees.parquet\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert row_count == 23, \"Employees was not loaded complete.\"\n",
    "\n",
    "print(\"Employees was loaded complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3d07cc",
   "metadata": {},
   "source": [
    "## customers table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = load_table_df(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feac8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    customers\n",
    "        .write\n",
    "        .format(\"parquet\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"s3a://datalake/exercises/raw/classicmodels/customers.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3419154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/raw/classicmodels/customers.parquet\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert row_count == 122, \"Customers was not loaded complete.\"\n",
    "\n",
    "print(\"Customers was loaded complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907aef7",
   "metadata": {},
   "source": [
    "## payments table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed9bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments = load_table_df(\"payments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b007bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    payments\n",
    "        .write\n",
    "        .format(\"parquet\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"s3a://datalake/exercises/raw/classicmodels/payments.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/raw/classicmodels/payments.parquet\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ade0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert row_count == 273, \"Payments was not loaded complete.\"\n",
    "\n",
    "print(\"Payments was loaded complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b211eea",
   "metadata": {},
   "source": [
    "## orders table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7484e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = load_table_df(\"orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de608365",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    orders\n",
    "        .write\n",
    "        .format(\"parquet\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"s3a://datalake/exercises/raw/classicmodels/orders.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/raw/classicmodels/orders.parquet\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert row_count == 326, \"Orders was not loaded complete.\"\n",
    "\n",
    "print(\"Orders was loaded complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b0e0d",
   "metadata": {},
   "source": [
    "## orderdetails table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderdetails = load_table_df(\"orderdetails\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb438b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    orderdetails\n",
    "        .write\n",
    "        .format(\"parquet\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"s3a://datalake/exercises/raw/classicmodels/orderdetails.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = spark.read.format(\"parquet\").load(\"s3a://datalake/exercises/raw/classicmodels/orderdetails.parquet\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert row_count == 2996, \"Orderdetails was not loaded complete\"\n",
    "\n",
    "print(\"Orderdetails was loaded complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
