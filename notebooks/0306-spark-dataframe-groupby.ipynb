{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc17238",
   "metadata": {},
   "source": [
    "# Data Frame GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d580a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ab1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleData = [\n",
    "    (\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000),\n",
    "]\n",
    "\n",
    "columns= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0520869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e93e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5ffab6",
   "metadata": {},
   "source": [
    "To aggregate dataframe, we will use `groupBy()`. `groupBy` has an alias `groupBy`. Choose them as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b8dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"department\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb2ae24",
   "metadata": {},
   "source": [
    "Notice that the return type of `groupBy` is `GroupedData`, not `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.groupBy(\"department\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac8454",
   "metadata": {},
   "source": [
    "We can use aggregate methods of `GroupedData` instance directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85011672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"department\").sum(\"salary\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8cdd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"department\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18fd6f",
   "metadata": {},
   "source": [
    "The aggregate methods of `GroupedData` supports multiple arguments to aggregate multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c16982",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    "  .groupBy(\"department\",\"state\")\n",
    "  .sum(\"salary\",\"bonus\")\n",
    "  .show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb0342",
   "metadata": {},
   "source": [
    "To alias a aggregate column, use aggregate functions in `pyspark.sql.functions` and chain it wit `alias()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupBy(\"department\")\n",
    "   .agg(\n",
    "     F.sum(\"salary\").alias(\"sum_salary\"),\n",
    "     F.avg(\"salary\").alias(\"avg_salary\"),\n",
    "     F.sum(\"bonus\").alias(\"sum_bonus\"),\n",
    "     F.avg(\"bonus\").alias(\"avg_bonus\"),\n",
    "   )\n",
    "   .show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aac02f",
   "metadata": {},
   "source": [
    "## GroupBy and Where"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ae0e7c",
   "metadata": {},
   "source": [
    "Using `where` after `groupby` operation means applying filtering after aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd37e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupBy(\"department\")\n",
    "   .agg(\n",
    "     F.sum(\"salary\").alias(\"sum_salary\"),\n",
    "     F.avg(\"salary\").alias(\"avg_salary\"),\n",
    "     F.sum(\"bonus\").alias(\"sum_bonus\"),\n",
    "     F.max(\"bonus\").alias(\"max_bonus\"),\n",
    "   )\n",
    "   .where(F.col(\"sum_bonus\") >= 50_000)\n",
    "   .show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc85b0",
   "metadata": {},
   "source": [
    "## GroupBy and Sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb9d362",
   "metadata": {},
   "source": [
    "After getting grouped data from aggregate, we can call `sort()` to order the aggregate column result as a normal dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fccbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGroup = (\n",
    "    df.groupBy(\"state\")\n",
    "      .agg(F.sum(\"salary\").alias(\"sum_salary\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100fb218",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGroup.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e64ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFilter = dfGroup.filter(dfGroup.sum_salary > 100_000)\n",
    "dfFilter.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFilter.sort(\"sum_salary\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a44f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFilter.sort(F.desc(\"sum_salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409f4b4",
   "metadata": {},
   "source": [
    "In summary, you can chain all operations applying with the grouped data frame within a single statement as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupBy(\"state\")\n",
    "   .agg(F.sum(\"salary\").alias(\"sum_salary\"))\n",
    "   .filter(F.col(\"sum_salary\") > 100_000)\n",
    "   .sort(F.desc(\"sum_salary\"))\n",
    "   .show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34c35be",
   "metadata": {},
   "source": [
    "## More about aggregate functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d096f",
   "metadata": {},
   "source": [
    "### approx_count_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958af8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(F.approx_count_distinct(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de1d753",
   "metadata": {},
   "source": [
    "### collect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4646310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(F.collect_list(\"salary\").alias(\"salaries\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"state\").agg(F.collect_list(\"salary\").alias(\"salaries\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2df57",
   "metadata": {},
   "source": [
    "### collect_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bae463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(F.collect_set(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc5177",
   "metadata": {},
   "source": [
    "### distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ddd136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"department\", \"salary\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82319f6c",
   "metadata": {},
   "source": [
    "### countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3615a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(F.countDistinct(\"department\", \"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed59cb3",
   "metadata": {},
   "source": [
    "### count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(F.count(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6199b0e9",
   "metadata": {},
   "source": [
    "### first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=False)\n",
    "df.select(F.first(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3513139",
   "metadata": {},
   "source": [
    "### last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(truncate=False)\n",
    "df.select(F.last(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf30c2",
   "metadata": {},
   "source": [
    "### kurtosis, skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.select(\n",
    "        F.kurtosis(\"salary\").alias(\"kurtosis_salary\"),\n",
    "        F.skewness(\"salary\").alias(\"skewness_salary\"),\n",
    "        F.stddev(\"salary\").alias(\"stddev_salary\"),\n",
    "        F.stddev_pop(\"salary\").alias(\"stddev_pop_salary\"),\n",
    "        F.variance(\"salary\").alias(\"variance_salary\"),\n",
    "    ).show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b868f9",
   "metadata": {},
   "source": [
    "### max, min, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e38454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    F.max(\"salary\").alias(\"max_salary\"),\n",
    "    F.avg(\"salary\").alias(\"avg_salary\"),\n",
    "    F.min(\"salary\").alias(\"min_salary\"),\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f70ffa",
   "metadata": {},
   "source": [
    "### sum, sumDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e40a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    F.sum(\"salary\"),\n",
    "    F.sum_distinct(\"salary\"),\n",
    ").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
